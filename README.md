# ğŸ§  Sleep Apnea Detection with Explainable CNN (XAI)

This project explores the use of a convolutional neural network (CNN) for detecting obstructive sleep apnea (OSA) events from biosignals, with a strong focus on **explainability** using  post-hoc methods like **Grad-CAM** and **SHAP**.

> **Project**: Explainable Neural Networks in the Medical Domain  
> **Institution**: HTWG Konstanz â€“ Ubiquitous Computing Lab  
> **Semester**: Summer Semester 2025  
> **Team Members**: Ahmed Adnan, JoÃ£o Pedro Cunha, Julian Ambrozy, Niklas Kaiser, Wiebke Prinz

---

## ğŸ©º Project Goal

To implement and evaluate a deep learning pipeline that classifies apnea events from biosignal windows and applies explainability techniques to interpret the modelâ€™s predictions in a clinical context.

---

## ğŸ“Š Datasets

We use publicly available, medically validated datasets:

- **SHHS2** â€“ Sleep Heart Health Study (Phase 2)  
- **MESA** â€“ Multi-Ethnic Study of Atherosclerosis

â¡ï¸ Downloadable from: [sleepdata.org](https://sleepdata.org)

**Biosignals used**:
- SpOâ‚‚ (Oxygen Saturation)
- HR (Heart Rate)
- Thoracic & Abdominal Respiratory Effort

Signals are preprocessed, downsampled to **1 Hz**, and segmented into **60-second windows**.

---

## ğŸ§± Model Architecture

We implement a CNN architecture inspired by:
- *de Souza et al. (2023), Frontiers in Neuroscience*  
- Structured for time-series biosignal classification

**Output:** Binary classification per window  
**Post-processing:** Apnea-Hypopnea Index (AHI) estimation

---

## ğŸ” Explainability Methods

Two post-hoc explainability techniques are integrated:

### ğŸ”¸ Grad-CAM (Gradient-weighted Class Activation Mapping)
- Adapted for 1D convolutional outputs
- Visualizes signal regions contributing most to each prediction

### ğŸ”¸ SHAP (SHapley Additive Explanations)
- Quantifies per-signal and per-feature contributions
- Generates both local and global interpretability outputs

---

## ğŸ› ï¸ Project Structure

```bash
sleep-apnea-cnn-xai/